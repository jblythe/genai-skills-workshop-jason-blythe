{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "u6ZGqBfvqZz7kWneiifLnUOm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u6ZGqBfvqZz7kWneiifLnUOm",
        "outputId": "e2287bf5-1da7-4a25-81da-c993c07cdd24",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.11/dist-packages (1.108.0)\n",
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.118.0-py2.py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.11/dist-packages (3.35.1)\n",
            "Collecting google-cloud-bigquery\n",
            "  Downloading google_cloud_bigquery-3.38.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (6.32.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (25.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.1.1)\n",
            "Collecting google-genai<2.0.0,>=1.37.0 (from google-cloud-aiplatform)\n",
            "  Downloading google_genai-1.39.1-py3-none-any.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.11.7)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (4.14.1)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.32.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.75.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.75.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (4.10.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.8.3)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from shapely<3.0.0->google-cloud-aiplatform) (2.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Downloading google_cloud_aiplatform-1.118.0-py2.py3-none-any.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_bigquery-3.38.0-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.3/259.3 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_genai-1.39.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.7/244.7 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-genai, google-cloud-bigquery, google-cloud-aiplatform\n",
            "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed google-cloud-aiplatform-1.118.0 google-cloud-bigquery-3.38.0 google-genai-1.39.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "07f15d8b857d433db6c4db91f62814e9",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade --user google-cloud-aiplatform google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0jaq-qwmn9lh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jaq-qwmn9lh",
        "outputId": "5ae84672-1908-48bd-8940-075629260d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qwiklabs-gcp-03-43ab15a95217\n"
          ]
        }
      ],
      "source": [
        "# Get project ID\n",
        "PROJECT_ID = ! gcloud config get-value project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
        "print(PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "wpCJi6HQoELC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpCJi6HQoELC",
        "outputId": "7e5e4823-5c45-4bd8-d5d4-1882181335ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import aiplatform\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "print(\"Initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e682b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "from google.api_core.exceptions import NotFound\n",
        "\n",
        "# BigQuery dataset/table configuration.\n",
        "DATASET_ID_REQUESTED = \"genai-skills-workshop\"\n",
        "# BigQuery converts hyphens to underscores in dataset IDs.\n",
        "DATASET_ID = DATASET_ID_REQUESTED.replace(\"-\", \"_\")\n",
        "TABLE_ID = \"aurora_bay_faqs\"\n",
        "GCS_URI = \"gs://labs.roitraining.com/aurora-bay-faqs/aurora-bay-faqs.csv\"\n",
        "\n",
        "# Reuse the same project inferred earlier in the notebook.\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# Build dataset reference anchored to the desired location.\n",
        "dataset_ref = bigquery.Dataset(f\"{PROJECT_ID}.{DATASET_ID}\")\n",
        "dataset_ref.location = LOCATION\n",
        "\n",
        "# Create the dataset if it does not yet exist.\n",
        "try:\n",
        "  bq_client.get_dataset(dataset_ref)\n",
        "  print(f\"Dataset `{PROJECT_ID}.{DATASET_ID}` already exists.\")\n",
        "except NotFound:\n",
        "  bq_client.create_dataset(dataset_ref)\n",
        "  print(f\"Created dataset `{PROJECT_ID}.{DATASET_ID}` in {LOCATION}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9311aee6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fully qualified table name we will load the CSV into.\n",
        "table_id = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "\n",
        "# Configure the ingestion job to use CSV autodetect and to overwrite any prior data.\n",
        "load_job_config = bigquery.LoadJobConfig(\n",
        "  source_format=bigquery.SourceFormat.CSV,\n",
        "  skip_leading_rows=1,\n",
        "  autodetect=True,\n",
        "  write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
        ")\n",
        "\n",
        "# Launch the load job from the public GCS bucket into BigQuery.\n",
        "load_job = bq_client.load_table_from_uri(GCS_URI, table_id, job_config=load_job_config)\n",
        "print(f\"Starting load job {load_job.job_id}\")\n",
        "\n",
        "# Wait for the load job to complete and fetch metadata for confirmation.\n",
        "load_job.result()\n",
        "table = bq_client.get_table(table_id)\n",
        "print(f\"Loaded {table.num_rows} rows into {table.full_table_id}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a63d9d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.cloud import bigquery_connection_v1\n",
        "\n",
        "# Connection configuration that allows BigQuery to call Vertex AI embeddings.\n",
        "CONNECTION_LOCATION = \"us\"\n",
        "CONNECTION_ID = \"vertex_ai_text_embeddings\"\n",
        "connection_parent = f\"projects/{PROJECT_ID}/locations/{CONNECTION_LOCATION}\"\n",
        "connection_name = f\"{connection_parent}/connections/{CONNECTION_ID}\"\n",
        "\n",
        "connection_client = bigquery_connection_v1.ConnectionServiceClient()\n",
        "\n",
        "# Reuse the connection when it already exists, otherwise create a new Vertex AI link.\n",
        "try:\n",
        "  connection = connection_client.get_connection(name=connection_name)\n",
        "  print(f\"Connection `{connection.name}` already exists.\")\n",
        "except NotFound:\n",
        "  connection = bigquery_connection_v1.types.Connection(\n",
        "      cloud_resource=bigquery_connection_v1.types.CloudResourceProperties(\n",
        "          service=bigquery_connection_v1.types.CloudResourceProperties.CloudResourceService.VERTEX_AI\n",
        "      )\n",
        "  )\n",
        "  connection = connection_client.create_connection(\n",
        "      parent=connection_parent,\n",
        "      connection_id=CONNECTION_ID,\n",
        "      connection=connection,\n",
        "  )\n",
        "  print(f\"Created connection `{connection.name}` for Vertex AI embeddings.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c07c034",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a remote BigQuery ML model that proxies requests to the Vertex AI text-embedding-005 endpoint.\n",
        "remote_model_sql = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{DATASET_ID}.embedding_model`\n",
        "REMOTE WITH CONNECTION `{PROJECT_ID}.{CONNECTION_LOCATION}.{CONNECTION_ID}`\n",
        "OPTIONS (\n",
        "  endpoint = 'text-embedding-005',\n",
        "  location = '{LOCATION}'\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# Execute the DDL so the model can be used in subsequent ML.GENERATE_TEXT_EMBEDDING calls.\n",
        "query_job = bq_client.query(remote_model_sql)\n",
        "query_job.result()\n",
        "print(f\"Created or updated remote model `{PROJECT_ID}.{DATASET_ID}.embedding_model` targeting text-embedding-005.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c34f11f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect the newly loaded table to understand available fields for downstream processing.\n",
        "table = bq_client.get_table(table_id)\n",
        "print(\"Schema for aurora_bay_faqs:\")\n",
        "for field in table.schema:\n",
        "  print(f\"  {field.name}: {field.field_type}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2082fa5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Materialize a table that stores concatenated Q/A text alongside its embedding vector.\n",
        "EMBEDDING_TABLE_ID = \"aurora_bay_faqs_with_embeddings\"\n",
        "embedding_table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{EMBEDDING_TABLE_ID}\"\n",
        "\n",
        "embedding_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{embedding_table_ref}` AS\n",
        "SELECT\n",
        "  question,\n",
        "  answer,\n",
        "  CONCAT(question, ': ', answer) AS qa_text,\n",
        "  ML.GENERATE_TEXT_EMBEDDING(\n",
        "    MODEL `{PROJECT_ID}.{DATASET_ID}.embedding_model`,\n",
        "    STRUCT(CONCAT(question, ': ', answer) AS content)\n",
        "  ) AS qa_embedding\n",
        "FROM `{table_id}`\n",
        "WHERE question IS NOT NULL AND answer IS NOT NULL;\n",
        "\"\"\"\n",
        "\n",
        "# Run the transformation query and wait for completion.\n",
        "embedding_job = bq_client.query(embedding_sql)\n",
        "embedding_job.result()\n",
        "print(f\"Created table `{embedding_table_ref}` with concatenated QA embeddings.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u65oV6zPoGSy",
      "metadata": {
        "id": "u65oV6zPoGSy"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "def answer_question_gemini(prompt):\n",
        "  \"\"\"Invoke Gemini with consistent generation settings to answer a prompt.\"\"\"\n",
        "  model = GenerativeModel(\"gemini-2.5-flash-lite\")\n",
        "  response = model.generate_content(\n",
        "    prompt,\n",
        "    generation_config={\n",
        "        \"max_output_tokens\": 8192,\n",
        "        \"temperature\": 0.5,\n",
        "        \"top_p\": 0.5,\n",
        "        \"top_k\": 10,\n",
        "    },\n",
        "  stream=False,\n",
        "  )\n",
        "  try:\n",
        "    return response.text\n",
        "  except:\n",
        "    print(\"An Error Ocuured Cleaning the Data\")\n",
        "    return \"An Error Ocuured Cleaning the Data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YCgf9L4toQ3U",
      "metadata": {
        "id": "YCgf9L4toQ3U"
      },
      "outputs": [],
      "source": [
        "def run_search(question):\n",
        "  from google.cloud import bigquery\n",
        "\n",
        "  client = bigquery.Client()\n",
        "\n",
        "  # Perform a vector search over the FAQ embedding table, using the remote model\n",
        "  # to embed the incoming natural language question on the fly.\n",
        "  sql = f\"\"\"\n",
        "      SELECT base.question, base.answer\n",
        "      FROM VECTOR_SEARCH(\n",
        "      TABLE `{embedding_table_ref}`, 'qa_embedding',\n",
        "      (\n",
        "      SELECT text_embedding, content AS query\n",
        "      FROM ML.GENERATE_TEXT_EMBEDDING(MODEL `{PROJECT_ID}.{DATASET_ID}.embedding_model`,\n",
        "          (SELECT @question AS content))),\n",
        "      top_k => 5)\n",
        "      \"\"\"\n",
        "\n",
        "  # Bind the user-entered question as a parameter to avoid SQL injection and reuse cached plans.\n",
        "  job_config = bigquery.QueryJobConfig(\n",
        "    query_parameters=[\n",
        "        bigquery.ScalarQueryParameter(\"question\", \"STRING\", question),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  query_job = client.query(sql, job_config=job_config)\n",
        "\n",
        "  # Format retrieved Q/A pairs as plain text paragraphs for downstream prompting.\n",
        "  rows = []\n",
        "  for row in query_job:\n",
        "    rows.append(f\"Q: {row.question}\\nA: {row.answer}\")\n",
        "\n",
        "  return \"\\n\\n\".join(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h6chC55poWof",
      "metadata": {
        "id": "h6chC55poWof"
      },
      "outputs": [],
      "source": [
        "def build_prompt(data, question):\n",
        "  \"\"\"Wrap retrieved context in a simple instruction-following prompt.\"\"\"\n",
        "  prompt = \"\"\"\n",
        "    Instructions: Answer the question using the following Context.\n",
        "\n",
        "    Context: {0}\n",
        "\n",
        "    Question: {1}\n",
        "  \"\"\".format(data, question)\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kpiT01ZXoZok",
      "metadata": {
        "id": "kpiT01ZXoZok"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "def answer_question(question):\n",
        "  \"\"\"Retrieve FAQ context, expose it inline, and ask Gemini for a final answer.\"\"\"\n",
        "\n",
        "  data = run_search(question)\n",
        "  display(\"Retrieved Data:\")\n",
        "  display(data)\n",
        "  display(\" . . . \")\n",
        "  prompt = build_prompt(data, question)\n",
        "  answer_gemini = answer_question_gemini(prompt)\n",
        "\n",
        "  return answer_gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "HHAjjSX-odDk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "HHAjjSX-odDk",
        "outputId": "943cbf72-4871-4a3c-858b-f1100a54d626"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Retrieved Data:'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Most areas of the US saw their economy continue to expand in December and early January, the US Federal Reserve said in its latest Beige Book report.\\n\\nOf the 12 US regions it identifies for the study, 11 showed stronger economic growth, with only the Cleveland area falling behind with a \"mixed\" rating. Consumer spending was higher in December than November, and festive sales were also up on 2003. The employment picture also improved, the Fed said.\\n\\n\"Labour markets firmed in a number of districts, but wage pressures generally remained modest,\" the Beige Book said. \"Several districts reported higher prices for building materials and manufacturing inputs, but most reported steady or only slightly higher overall price levels.\" The report added that residential real estate activity remained strong and that commercial real estate activity strengthened in most districts. \"Office leasing was especially brisk in Washington DC, and New York City, two of the nation\\'s strongest commercial markets,\" the Fed said.\\n\\nThe gap between US exports and imports has widened to more than $60bn (£31.7bn), an all-time record.\\n\\nFigures from the Commerce Department for November showed exports down 2.3% to $95.6bn, while imports grew 1.3% to $155.8bn on rising consumer demand. Part of the expanding deficit came from high prices for oil imports. But the numbers suggested the sliding dollar - which makes exports less expensive - has had little impact, and could indicate slowing economic growth.\\n\\nThe trade deficit - far bigger than the $54bn widely expected on Wall Street - prompted a rapid response from the currency markets.\\n\\nBy 1650 GMT, the dollar was trading against the euro at $1.3280, almost a cent and a half weaker than before the announcement. Against the pound, the dollar was down about 0.7% at $1,8923. \"The dollar\\'s fall has been sudden, violent and appropriate given this number,\" said Brian Taylor of Wells Fargo in Minneapolis. \"Recent exchange rate movements certainly haven\\'t had any impact yet.\" Treasury Secretary John Snow put a brave face on the news, saying it was a sign of strong economic expansion. \"The economy is growing at such a fast rate that it is generating lots of disposable income... some of which is used to buy goods from our trading partners.\"\\n\\nAlthough the White House officially still backs the US\\'s traditional \"strong dollar\" policy, it has tacitly indicated that it would be happy if the slide continued. The dollar has fallen by 50% against the euro - as well as by 30% against the yen - in the past three years. The main catalyst, most economists accept, is the large budget deficit on the one hand, and the current account deficit - the difference between the flow of money in and out of the US - on the other. The trade deficit is a large part of the latter. In November, the fall in exports was largely due to a decline in sales of industrial supplies and materials such as chemicals, as well as of cars, consumer goods and food. One small bright spot for US policy-makers was a slight decline in the deficit with China, often blamed for job losses and other economic woes. Although China\\'s overall trade surplus is expanding, according to Chinese government figures, the Commerce Department revealed the US\\'s deficit with China was $19.6bn in November, down from $19.7bn the month before. But the deficit with Japan was at its worst in more than four years.\\n\\nThe US economy added 337,000 jobs in October - a seven-month high and far more than Wall Street expectations.\\n\\nIn a welcome economic boost for newly re-elected President George W Bush, the Labor Department figures come after a slow summer of weak jobs gains. Jobs were created in every sector of the US economy except manufacturing. While the separate unemployment rate went up to 5.5% from 5.4% in September, this was because more people were now actively seeking work.\\n\\nThe 337,000 new jobs added to US payrolls in October was twice the 169,000 figure that Wall Street economists had forecast. In addition, the Labor Department revised up the number of jobs created in the two previous months - to 139,000 in September instead of 96,000, and to 198,000 in August instead of 128,000. The better than expected jobs data had an immediate upward effect on stocks in New York, with the main Dow Jones index gaining 45.4 points to 10,360 by late morning trading. \"It looks like the job situation is improving and that this will support consumer spending going into the holidays, and offset some of the drag caused by high oil prices this year,\" said economist Gary Thayer of AG Edwards & Sons.\\n\\nOther analysts said the upbeat jobs data made it more likely that the US Federal Reserve would increase interest rates by a quarter of a percentage point to 2% when it meets next week. \"It should empower the Fed to clearly do something,\" said Robert MacIntosh, chief economist with Eaton Vance Management in Boston. Kathleen Utgoff, commissioner of the Bureau of Labor, said many of the 71,000 new construction jobs added in October were involved in rebuilding and clean-up work in Florida, and neighbouring Deep South states, following four hurricanes in August and September. The dollar rose temporarily on the job creation news before falling back to a new record low against the euro, as investors returned their attention to other economic factors, such as the US\\'s record trade deficit. There is also speculation that President Bush will deliberately try to keep the dollar low in order to assist a growth in exports.\\n\\nThe US created fewer jobs than expected in January, but a fall in jobseekers pushed the unemployment rate to its lowest level in three years.\\n\\nAccording to Labor Department figures, US firms added only 146,000 jobs in January. The gain in non-farm payrolls was below market expectations of 190,000 new jobs. Nevertheless it was enough to push down the unemployment rate to 5.2%, its lowest level since September 2001. The job gains mean that President Bush can celebrate - albeit by a very fine margin - a net growth in jobs in the US economy in his first term in office. He presided over a net fall in jobs up to last November\\'s Presidential election - the first President to do so since Herbert Hoover. As a result, job creation became a key issue in last year\\'s election. However, when adding December and January\\'s figures, the administration\\'s first term jobs record ended in positive territory.\\n\\nThe Labor Department also said it had revised down the jobs gains in December 2004, from 157,000 to 133,000.\\n\\nAnalysts said the growth in new jobs was not as strong as could be expected given the favourable economic conditions. \"It suggests that employment is continuing to expand at a moderate pace,\" said Rick Egelton, deputy chief economist at BMO Financial Group. \"We are not getting the boost to employment that we would have got given the low value of the dollar and the still relatively low interest rate environment.\" \"The economy is producing a moderate but not a satisfying amount of job growth,\" said Ken Mayland, president of ClearView Economics. \"That means there are a limited number of new opportunities for workers.\"\\n\\nGermany\\'s economy, the biggest among the 12 countries sharing the euro, grew at its fastest rate in four years during 2004, driven by strong exports.\\n\\nGross domestic product (GDP) rose by 1.7% last year, the statistical office said. The economy contracted in 2003. Foreign sales increased by 8.2% last year, compared with a 0.3% slide in private consumption. Concerns remain, however, over the strength of the euro, weak domestic demand and a sluggish labour market. The European Central Bank (ECB) left its benchmark interest rate unchanged at 2% on Thursday. It is the nineteenth month in a row that the ECB has not moved borrowing costs. Economists predict that an increase is unlikely to come until the second half of 2005, with growth set to sputter rather than ignite.\\n\\n\"During 2004 we profited from the fact that the world economy was strong,\" said Stefan Schilbe, analyst at HSBC Trinkaus & Burkhardt. \"If exports weaken and domestic growth remains poor, we cannot expect much from 2005.\" Many German consumers have been spooked and unsettled by government attempts to reform the welfare state and corporate environment. Major companies including Volkswagen, DaimlerChrysler and Siemens have spent much of 2004 in tough talks with unions about trimming jobs and costs. They have also warned there are more cost cutting measures on the horizon.\\n\\n'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' . . . '"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'User Question:'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tell me about the US Economy'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'--------------------------------'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Gemini Answer:'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Based on the context provided, here is a summary of the US Economy:\\n\\n**Overall Growth and Consumer Spending:**\\n*   The US economy continued to expand in December and early January, with 11 of the 12 regions identified by the Federal Reserve showing stronger economic growth.\\n*   Consumer spending was higher in December than in November, and festive sales were up compared to 2003.\\n*   Treasury Secretary John Snow stated the economy was \"growing at such a fast rate that it is generating lots of disposable income.\"\\n\\n**Employment:**\\n*   The employment picture improved, with labor markets firming up in a number of districts.\\n*   October saw a significant and better-than-expected addition of 337,000 jobs, a seven-month high.\\n*   January saw a smaller-than-expected gain of 146,000 jobs, but the unemployment rate fell to 5.2%, its lowest level in three years.\\n*   Analysts described the job growth as \"moderate but not a satisfying amount.\"\\n\\n**Trade and the Dollar:**\\n*   The trade deficit (the gap between exports and imports) widened to a record high of over $60 billion in November. Exports fell by 2.3% while imports grew by 1.3%.\\n*   The sliding value of the dollar had not yet had a significant impact on improving the trade balance.\\n*   The dollar fell to a new record low against the euro following the trade deficit news. The White House has tacitly indicated it would be happy if the dollar\\'s slide continued, potentially to assist export growth.\\n\\n**Prices and Real Estate:**\\n*   While prices for building materials and manufacturing inputs were higher, overall price levels were reported as \"steady or only slightly higher,\" and wage pressures remained modest.\\n*   Residential real estate activity was strong, and commercial real estate strengthened in most districts, with office leasing being particularly brisk in Washington D.C. and New York City.'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "QUESTION = \"Tell me about the US Economy\"\n",
        "\n",
        "answer_gemini = answer_question(QUESTION)\n",
        "display(\"User Question:\")\n",
        "display(QUESTION)\n",
        "display(\"--------------------------------\")\n",
        "display(\"Gemini Answer:\")\n",
        "display(answer_gemini)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "student-01-a5667f77b4cf (Oct 1, 2025, 12:33:11 PM)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
