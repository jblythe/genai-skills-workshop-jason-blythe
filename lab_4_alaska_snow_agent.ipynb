{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 4 · Alaska Snow Department Agent\n",
        "\n",
        "This lab guides you through building a prototype Retrieval-Augmented Generation (RAG) chatbot for the Alaska Department of Snow (ADS). The notebook orchestrates data ingestion from Google Cloud Storage (GCS), creation of a Vertex AI Vector Search datastore, agent orchestration components, safety mechanisms, evaluation workflows, and deployment assets.\n",
        "\n",
        "> **Project:** `qwiklabs-gcp-04-ee8165cd97c8`\n",
        ">\n",
        "> **Region:** `us-central1`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup & Configuration\n",
        "\n",
        "The following cells configure the Google Cloud SDK, authenticate, and set global variables used throughout the notebook. Run each cell sequentially before moving on to the ingestion pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install --quiet google-cloud-storage google-cloud-aiplatform vertexai langchain google-cloud-discoveryengine matplotlib networkx pypdf beautifulsoup4 tiktoken\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import auth\n",
        "\n",
        "# Authenticate with Google Cloud\n",
        "try:\n",
        "    auth.authenticate_user()\n",
        "except ModuleNotFoundError:\n",
        "    # For environments outside Colab, fall back to ADC or local gcloud auth\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ID = \"qwiklabs-gcp-04-ee8165cd97c8\"\n",
        "LOCATION = \"us-central1\"\n",
        "GCS_BUCKET = \"labs.roitraining.com\"\n",
        "GCS_PREFIX = \"alaska-dept-of-snow\"\n",
        "VERTEX_SEARCH_ENGINE_ID = \"ads-faq-datastore\"\n",
        "DATASET_DISPLAY_NAME = \"ads_faq_documents\"\n",
        "\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "os.environ[\"VERTEXAI_PROJECT\"] = PROJECT_ID\n",
        "os.environ[\"VERTEXAI_LOCATION\"] = LOCATION\n",
        "\n",
        "print(f\"Project: {PROJECT_ID}\\nLocation: {LOCATION}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dialogflow Data Store Provisioning (GCS Unstructured Data)\n",
        "\n",
        "This section provisions a Dialogflow-compatible data store backed by Vertex AI Search. The store ingests unstructured FAQ content directly from the ADS GCS bucket—no local downloads or manual chunking required.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "from google.api_core.operation import Operation\n",
        "from google.cloud import discoveryengine_v1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DISCOVERY_LOCATION = \"global\"\n",
        "COLLECTION_ID = \"default_collection\"\n",
        "DATA_STORE_ID = \"ads-faq-unstructured\"\n",
        "DATA_STORE_DISPLAY_NAME = \"ADS FAQ Data Store\"\n",
        "SERVING_CONFIG_ID = \"default_serving_config\"\n",
        "\n",
        "# Dialogflow (Vertex AI Search) clients\n",
        "_data_store_client = discoveryengine_v1.DataStoreServiceClient()\n",
        "_document_service_client = discoveryengine_v1.DocumentServiceClient()\n",
        "_search_service_client = discoveryengine_v1.SearchServiceClient()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _collection_path() -> str:\n",
        "    return f\"projects/{PROJECT_ID}/locations/{DISCOVERY_LOCATION}/collections/{COLLECTION_ID}\"\n",
        "\n",
        "\n",
        "def data_store_path() -> str:\n",
        "    return _data_store_client.data_store_path(\n",
        "        PROJECT_ID,\n",
        "        DISCOVERY_LOCATION,\n",
        "        DATA_STORE_ID,\n",
        "    )\n",
        "\n",
        "\n",
        "def serving_config_path() -> str:\n",
        "    return _search_service_client.serving_config_path(\n",
        "        project=PROJECT_ID,\n",
        "        location=DISCOVERY_LOCATION,\n",
        "        data_store=DATA_STORE_ID,\n",
        "        serving_config=SERVING_CONFIG_ID,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_data_store(display_name: str = DATA_STORE_DISPLAY_NAME) -> discoveryengine_v1.DataStore:\n",
        "    \"\"\"Create the data store if missing; return the active store.\"\"\"\n",
        "    target_name = data_store_path()\n",
        "    list_request = discoveryengine_v1.ListDataStoresRequest(parent=_collection_path())\n",
        "    for existing in _data_store_client.list_data_stores(request=list_request):\n",
        "        if existing.name == target_name:\n",
        "            print(f\"Data store already exists: {existing.name}\")\n",
        "            return existing\n",
        "\n",
        "    data_store = discoveryengine_v1.DataStore(\n",
        "        display_name=display_name,\n",
        "        industry_vertical=discoveryengine_v1.IndustryVertical.GENERIC,\n",
        "        solution_types=[discoveryengine_v1.SolutionType.SOLUTION_TYPE_SEARCH],\n",
        "    )\n",
        "    operation: Operation = _data_store_client.create_data_store(\n",
        "        request=discoveryengine_v1.CreateDataStoreRequest(\n",
        "            parent=_collection_path(),\n",
        "            data_store=data_store,\n",
        "            data_store_id=DATA_STORE_ID,\n",
        "        )\n",
        "    )\n",
        "    result = operation.result()\n",
        "    print(f\"Created data store: {result.name}\")\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def import_gcs_documents(prefix: str = GCS_PREFIX) -> discoveryengine_v1.ImportDocumentsResponse:\n",
        "    \"\"\"Trigger asynchronous ingestion of GCS documents into the data store.\"\"\"\n",
        "    gcs_uri = f\"gs://{GCS_BUCKET}/{prefix.rstrip('/')}/**\"\n",
        "    branch = _document_service_client.branch_path(\n",
        "        project=PROJECT_ID,\n",
        "        location=DISCOVERY_LOCATION,\n",
        "        data_store=DATA_STORE_ID,\n",
        "        branch=\"default_branch\",\n",
        "    )\n",
        "    request = discoveryengine_v1.ImportDocumentsRequest(\n",
        "        parent=branch,\n",
        "        gcs_source=discoveryengine_v1.GcsSource(input_uris=[gcs_uri]),\n",
        "        auto_generate_ids=True,\n",
        "        reconciliation_mode=discoveryengine_v1.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL,\n",
        "    )\n",
        "    operation: Operation = _document_service_client.import_documents(request=request)\n",
        "    response = operation.result()\n",
        "    print(\n",
        "        \"Import finished:\",\n",
        "        f\"success_count={response.success_count}\",\n",
        "        f\"error_count={response.error_count}\",\n",
        "    )\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Model Armor Template Provisioning\n",
        "\n",
        "These helpers create (or reuse) Model Armor prompt/response templates. They are required for runtime sanitization inside the Cloud Run backend.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import google.auth\n",
        "from google.auth.transport.requests import AuthorizedSession, Request\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_ARMOR_API_BASE = \"https://modelarmor.us-central1.rep.googleapis.com/v1\"\n",
        "MODEL_ARMOR_PARENT = f\"projects/{PROJECT_ID}/locations/{LOCATION}\"\n",
        "PROMPT_TEMPLATE_ID = \"ads-snow-prompt-template\"\n",
        "RESPONSE_TEMPLATE_ID = \"ads-snow-response-template\"\n",
        "\n",
        "PROMPT_TEMPLATE_BODY = {\n",
        "    \"filterConfig\": {\n",
        "        \"raiSettings\": {\n",
        "            \"raiFilters\": [\n",
        "                {\"filterType\": \"HATE_SPEECH\", \"confidenceLevel\": \"MEDIUM_AND_ABOVE\"},\n",
        "                {\"filterType\": \"DANGEROUS\", \"confidenceLevel\": \"MEDIUM_AND_ABOVE\"},\n",
        "                {\"filterType\": \"SEXUALLY_EXPLICIT\", \"confidenceLevel\": \"MEDIUM_AND_ABOVE\"},\n",
        "                {\"filterType\": \"HARASSMENT\", \"confidenceLevel\": \"MEDIUM_AND_ABOVE\"},\n",
        "            ]\n",
        "        },\n",
        "        \"sdpSettings\": {\n",
        "            \"basicConfig\": {\"filterEnforcement\": \"ENABLED\"}\n",
        "        },\n",
        "        \"piAndJailbreakFilterSettings\": {\n",
        "            \"filterEnforcement\": \"ENABLED\",\n",
        "            \"confidenceLevel\": \"MEDIUM_AND_ABOVE\",\n",
        "        },\n",
        "    },\n",
        "    \"templateMetadata\": {\n",
        "        \"multiLanguageDetection\": {}\n",
        "    },\n",
        "}\n",
        "\n",
        "RESPONSE_TEMPLATE_BODY = {\n",
        "    \"filterConfig\": {\n",
        "        \"raiSettings\": {\n",
        "            \"raiFilters\": [\n",
        "                {\"filterType\": \"HATE_SPEECH\", \"confidenceLevel\": \"MEDIUM_AND_ABOVE\"},\n",
        "                {\"filterType\": \"DANGEROUS\", \"confidenceLevel\": \"MEDIUM_AND_ABOVE\"},\n",
        "                {\"filterType\": \"SEXUALLY_EXPLICIT\", \"confidenceLevel\": \"MEDIUM_AND_ABOVE\"},\n",
        "                {\"filterType\": \"HARASSMENT\", \"confidenceLevel\": \"MEDIUM_AND_ABOVE\"},\n",
        "            ]\n",
        "        },\n",
        "        \"sdpSettings\": {\n",
        "            \"basicConfig\": {\"filterEnforcement\": \"ENABLED\"}\n",
        "        },\n",
        "    },\n",
        "    \"templateMetadata\": {\n",
        "        \"multiLanguageDetection\": {}\n",
        "    },\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _model_armor_session() -> AuthorizedSession:\n",
        "    credentials, _ = google.auth.default()\n",
        "    credentials.refresh(Request())\n",
        "    return AuthorizedSession(credentials)\n",
        "\n",
        "\n",
        "def ensure_template_exists(template_id: str, payload: dict) -> str:\n",
        "    session = _model_armor_session()\n",
        "    name = f\"{MODEL_ARMOR_PARENT}/templates/{template_id}\"\n",
        "    get_url = f\"{MODEL_ARMOR_API_BASE}/{MODEL_ARMOR_PARENT}/templates/{template_id}\"\n",
        "    response = session.get(get_url, timeout=20)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"name\", name)\n",
        "    if response.status_code not in {400, 404}:\n",
        "        raise RuntimeError(f\"Failed to fetch template {template_id}: {response.status_code} {response.text}\")\n",
        "\n",
        "    create_url = f\"{MODEL_ARMOR_API_BASE}/{MODEL_ARMOR_PARENT}/templates?templateId={template_id}\"\n",
        "    operation = session.post(create_url, json=payload, timeout=30)\n",
        "    operation.raise_for_status()\n",
        "    op_name = operation.json().get(\"name\")\n",
        "    if not op_name:\n",
        "        raise RuntimeError(\"Model Armor template creation did not return an operation name\")\n",
        "\n",
        "    status_url = f\"{MODEL_ARMOR_API_BASE}/{op_name}\"\n",
        "    while True:\n",
        "        status = session.get(status_url, timeout=20)\n",
        "        status.raise_for_status()\n",
        "        body = status.json()\n",
        "        if body.get(\"done\"):\n",
        "            return body.get(\"response\", {}).get(\"name\", name)\n",
        "        time.sleep(2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_model_armor_templates() -> dict:\n",
        "    prompt_template = ensure_template_exists(PROMPT_TEMPLATE_ID, PROMPT_TEMPLATE_BODY)\n",
        "    response_template = ensure_template_exists(RESPONSE_TEMPLATE_ID, RESPONSE_TEMPLATE_BODY)\n",
        "    return {\n",
        "        \"prompt_template\": prompt_template,\n",
        "        \"response_template\": response_template,\n",
        "    }\n",
        "\n",
        "# Example usage:\n",
        "# model_armor_templates = initialize_model_armor_templates()\n",
        "# model_armor_templates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Tip:** Run `initialize_model_armor_templates()` once per environment to create the prompt and response templates. Capture the returned resource names for your Cloud Run deployment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Tip:** Run `initialize_model_armor_templates()` once per environment to create the prompt/response templates. Record the returned resource names for use in the backend deployment scripts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_dialogflow_datastore() -> dict:\n",
        "    \"\"\"Create the data store if needed and import the latest documents.\"\"\"\n",
        "    data_store = ensure_data_store()\n",
        "    import_response = import_gcs_documents()\n",
        "    return {\n",
        "        \"data_store\": data_store.name,\n",
        "        \"success_count\": import_response.success_count,\n",
        "        \"error_count\": import_response.error_count,\n",
        "        \"serving_config\": serving_config_path(),\n",
        "    }\n",
        "\n",
        "# Example usage (long-running operation):\n",
        "# datastore_summary = initialize_dialogflow_datastore()\n",
        "# datastore_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trigger Dialogflow data store provisioning and ingestion (long-running)\n",
        "# Uncomment the lines below to create/update the data store in your project.\n",
        "# datastore_summary = initialize_dialogflow_datastore()\n",
        "# datastore_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note:** Dialogflow data stores are billed via Vertex AI Search. Run the import job against a development project if you only need to validate configuration before promoting to production.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Agent Orchestration & Backend Interface\n",
        "\n",
        "The prototype agent uses a RAG pipeline with Vertex AI Gemini for grounded responses. The following cells configure retrievers, prompt templates, and FastAPI endpoints for the Cloud Run deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
        "\n",
        "CHAT_MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
        "\n",
        "retrieval_generation_system_prompt = \"\"\"You are the Alaska Department of Snow virtual assistant. Use only the provided documents to answer citizen questions about snow removal, permits, and department operations. If the answer is unavailable in the documents, acknowledge the limitation and escalate to human support.\"\"\"\n",
        "\n",
        "response_style_prompt = \"\"\"Follow these guidelines:\n",
        "- Keep answers under 150 words\n",
        "- Reference relevant policies when available\n",
        "- Suggest online self-service options before instructing to call the department\n",
        "- Use inclusive, respectful language\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_context(query: str, serving_config: Optional[str] = None, top_k: int = 6) -> List[dict]:\n",
        "    config_name = serving_config or serving_config_path()\n",
        "    search_request = discoveryengine_v1.SearchRequest(\n",
        "        serving_config=config_name,\n",
        "        query=query,\n",
        "        page_size=top_k,\n",
        "    )\n",
        "    documents = []\n",
        "    for result in _search_service_client.search(request=search_request):\n",
        "        document = result.document\n",
        "        documents.append(\n",
        "            {\n",
        "                \"id\": document.id,\n",
        "                \"content\": document.content,\n",
        "                \"source\": document.content_uri,\n",
        "            }\n",
        "        )\n",
        "    return documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_prompt_with_context(question: str, documents: List[dict]) -> str:\n",
        "    context_blocks = []\n",
        "    for doc in documents:\n",
        "        text = (doc.get(\"content\") or \"\").strip()\n",
        "        source = doc.get(\"source\") or doc.get(\"id\", \"unknown\")\n",
        "        context_blocks.append(f\"Source: {source}\\n{text}\")\n",
        "    context = \"\\n\\n\".join(context_blocks)\n",
        "    prompt = f\"{retrieval_generation_system_prompt}\\n\\n{response_style_prompt}\\n\\nContext:\\n{context}\\n\\nUser question: {question}\\n\\nAnswer:\"\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_answer(question: str, serving_config: Optional[str] = None) -> dict:\n",
        "    documents = retrieve_context(question=question, serving_config=serving_config)\n",
        "    prompt = build_prompt_with_context(question, documents)\n",
        "    model = GenerativeModel(CHAT_MODEL_NAME)\n",
        "    response = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=GenerationConfig(temperature=0.2, top_p=0.95, max_output_tokens=512),\n",
        "    )\n",
        "    return {\n",
        "        \"answer\": response.text,\n",
        "        \"context\": documents,\n",
        "        \"prompt\": prompt,\n",
        "    }\n",
        "\n",
        "# Example usage (requires data store ingestion to be complete)\n",
        "# agent_response = generate_answer(\"How do I request residential snow removal?\", serving_config=serving_config_path())\n",
        "# agent_response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Safety Controls, Validation & Evaluation\n",
        "\n",
        "Safety guardrails enforce privacy policies, filter risky prompts, and validate model responses. This section introduces reusable filters, unit-test scaffolds, and an evaluation harness using the Google Generative AI Evaluation Service.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import tiktoken\n",
        "\n",
        "SENSITIVE_PATTERNS = {\n",
        "    \"pii_email\": re.compile(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", re.IGNORECASE),\n",
        "    \"pii_phone\": re.compile(r\"(\\+?1[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\"),\n",
        "    \"credit_card\": re.compile(r\"\\b(?:\\d[ -]*?){13,16}\\b\"),\n",
        "}\n",
        "\n",
        "ALLOWED_TOPICS = [\n",
        "    \"snow removal\",\n",
        "    \"permits\",\n",
        "    \"parking bans\",\n",
        "    \"road conditions\",\n",
        "    \"department contact\",\n",
        "]\n",
        "\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    return len(enc.encode(text))\n",
        "\n",
        "\n",
        "class PromptSafetyError(Exception):\n",
        "    \"\"\"Raised when a prompt violates a safety rule.\"\"\"\n",
        "\n",
        "\n",
        "class SafetyRuleEngine:\n",
        "    def __init__(self, allow_topics: List[str]):\n",
        "        self.allow_topics = allow_topics\n",
        "\n",
        "    def validate_prompt(self, prompt: str) -> None:\n",
        "        if count_tokens(prompt) > 2048:\n",
        "            raise PromptSafetyError(\"Prompt exceeds maximum token limit (2048)\")\n",
        "        lower_prompt = prompt.lower()\n",
        "        if not any(topic in lower_prompt for topic in self.allow_topics):\n",
        "            raise PromptSafetyError(\"Prompt topic not allowed for ADS assistant\")\n",
        "        for label, pattern in SENSITIVE_PATTERNS.items():\n",
        "            if pattern.search(prompt):\n",
        "                raise PromptSafetyError(f\"Detected sensitive pattern: {label}\")\n",
        "\n",
        "    def validate_response(self, response: str, sources: List[str]) -> None:\n",
        "        for label, pattern in SENSITIVE_PATTERNS.items():\n",
        "            if pattern.search(response):\n",
        "                raise PromptSafetyError(f\"Response leaks sensitive data: {label}\")\n",
        "        if \"call 911\" in response.lower() and not any(\"emergency\" in s.lower() for s in sources):\n",
        "            raise PromptSafetyError(\"Response escalates emergency services without evidence\")\n",
        "\n",
        "\n",
        "safety_rules = SafetyRuleEngine(ALLOWED_TOPICS)\n",
        "\n",
        "\n",
        "def safe_generate(question: str, serving_config: Optional[str] = None) -> dict:\n",
        "    safety_rules.validate_prompt(question)\n",
        "    candidate = generate_answer(question=question, serving_config=serving_config)\n",
        "    safety_rules.validate_response(candidate[\"answer\"], [doc.get(\"source\", \"\") for doc in candidate[\"context\"]])\n",
        "    return candidate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UNIT_TESTS_CODE = \"\"\"import pytest\n",
        "from fastapi.testclient import TestClient\n",
        "from unittest.mock import patch, MagicMock\n",
        "\n",
        "from services.main import app, safety_rules, PromptSafetyError\n",
        "\n",
        "client = TestClient(app)\n",
        "\n",
        "\n",
        "def test_prompt_rejection_for_pii():\n",
        "    with pytest.raises(PromptSafetyError):\n",
        "        safety_rules.validate_prompt(\"My email is ops@ads.gov, please update\")\n",
        "\n",
        "\n",
        "def test_chat_endpoint_success(monkeypatch):\n",
        "    mock_endpoint = MagicMock()\n",
        "    mock_endpoint.match.return_value = [[MagicMock(metadata={\"text\": \"Snow removal policy\", \"source\": \"gs://demo\"})]]\n",
        "    monkeypatch.setattr(\"services.main.endpoint\", mock_endpoint)\n",
        "\n",
        "    mock_model = MagicMock()\n",
        "    mock_model.generate_content.return_value = MagicMock(text=\"Cleared sidewalks within 24 hours\")\n",
        "    monkeypatch.setattr(\"services.main.model\", mock_model)\n",
        "\n",
        "    response = client.post(\n",
        "        \"/chat\",\n",
        "        json={\"session_id\": \"test\", \"message\": \"How soon is residential snow cleared?\"},\n",
        "    )\n",
        "    assert response.status_code == 200\n",
        "    payload = response.json()\n",
        "    assert \"answer\" in payload and \"sources\" in payload\n",
        "\n",
        "\n",
        "def test_chat_endpoint_blocks_invalid_prompt(monkeypatch):\n",
        "    response = client.post(\n",
        "        \"/chat\",\n",
        "        json={\"session_id\": \"test\", \"message\": \"Here is my SSN 111-22-3333\"},\n",
        "    )\n",
        "    assert response.status_code == 422\n",
        "\"\"\"\n",
        "\n",
        "print(UNIT_TESTS_CODE.splitlines()[:12])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform_v1beta1\n",
        "\n",
        "def run_google_evaluation(index_endpoint_name: str, test_cases: List[dict]) -> dict:\n",
        "    \"\"\"Submit evaluation set to the Generative AI Evaluation Service.\"\"\"\n",
        "    client = aiplatform_v1beta1.EvaluationServiceClient()\n",
        "    dataset = aiplatform_v1beta1.Dataset(\n",
        "        display_name=\"ads_chatbot_eval\",\n",
        "        annotations=[\n",
        "            aiplatform_v1beta1.Dataset.Annotation(\n",
        "                instruction=case[\"question\"],\n",
        "                reference=case[\"expected\"],\n",
        "            )\n",
        "            for case in test_cases\n",
        "        ],\n",
        "    )\n",
        "    model_name = f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{CHAT_MODEL_NAME}\"\n",
        "    request = aiplatform_v1beta1.RunEvaluationRequest(\n",
        "        target_model=model_name,\n",
        "        dataset=dataset,\n",
        "        evaluation_job_spec=aiplatform_v1beta1.EvaluationJobSpec(\n",
        "            generative_metric_specs=[\n",
        "                aiplatform_v1beta1.GenerativeMetricSpec(\n",
        "                    metric_type=\"BLEU\",\n",
        "                ),\n",
        "                aiplatform_v1beta1.GenerativeMetricSpec(metric_type=\"ROUGE_L\"),\n",
        "            ],\n",
        "        ),\n",
        "    )\n",
        "    operation = client.run_evaluation(request=request)\n",
        "    print(\"Evaluation job submitted:\", operation.operation.name)\n",
        "    return {\"operation_name\": operation.operation.name}\n",
        "\n",
        "\n",
        "EVAL_TEST_CASES = [\n",
        "    {\"question\": \"What is the process to request residential snow removal?\", \"expected\": \"Explain the online request form and eligibility.\"},\n",
        "    {\"question\": \"Who do I call for emergency plowing?\", \"expected\": \"Direct to emergency hotline and note expected response time.\"},\n",
        "]\n",
        "\n",
        "# eval_job = run_google_evaluation(\"projects/.../locations/.../indexEndpoints/...\", EVAL_TEST_CASES)\n",
        "# eval_job\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation Workflow Steps\n",
        "\n",
        "1. Generate or curate a set of gold-standard question/answer pairs covering top call drivers.\n",
        "2. Run `run_google_evaluation` to score responses across BLEU/ROUGE (and optionally safety metrics).\n",
        "3. Export evaluation metrics to BigQuery for trend monitoring.\n",
        "4. Gate deployments if evaluation scores fall below the thresholds defined in the change management plan.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Deployment & Frontend Assets\n",
        "\n",
        "This section captures reference assets for the Cloud Run backend and React chat interface wired to the ADS agent API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### React Frontend Deployment Notes\n",
        "\n",
        "- Host the static site on Firebase Hosting or Cloud Storage behind a CDN.\n",
        "- Configure `VITE_API_URL` with the Cloud Run HTTPS endpoint.\n",
        "- Enforce HTTPS and set CORS allowlist to production hostname.\n",
        "- Add Google Analytics or internal telemetry hooks to measure deflected call volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Architecture & Operations Summary\n",
        "\n",
        "The ADS assistant integrates Vertex AI services with secure logging, evaluation, and deployment workflows. Use the following checklist while preparing the executive demo:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Security:** Service-to-service authentication via Workload Identity Federation; Cloud Logging captures prompt/response metadata without PII.\n",
        "- **Privacy:** Prompt and response validators enforce ADS policies before reaching the model and prior to returning to the user.\n",
        "- **Accuracy:** RAG grounding documents are versioned; evaluation scores must exceed 0.5 BLEU / 0.6 ROUGE_L prior to release.\n",
        "- **Reliability:** Cloud Run horizontal auto-scaling (min instances = 1, max = 10) and uptime checks configured in Cloud Monitoring.\n",
        "- **Cost:** Vector Search auto-scaling configured for 1000 queries/min; nightly cleanup job removes stale sessions and cold data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "flow_nodes = [\n",
        "    \"Resident Web Chat\",\n",
        "    \"React Frontend\",\n",
        "    \"Cloud Run API\",\n",
        "    \"Prompt Filters\",\n",
        "    \"Dialogflow Data Store\",\n",
        "    \"Gemini Model\",\n",
        "    \"Response Validators\",\n",
        "    \"Cloud Logging\",\n",
        "]\n",
        "\n",
        "flow_edges = [\n",
        "    (\"Resident Web Chat\", \"React Frontend\"),\n",
        "    (\"React Frontend\", \"Cloud Run API\"),\n",
        "    (\"Cloud Run API\", \"Prompt Filters\"),\n",
        "    (\"Prompt Filters\", \"Dialogflow Data Store\"),\n",
        "    (\"Dialogflow Data Store\", \"Gemini Model\"),\n",
        "    (\"Gemini Model\", \"Response Validators\"),\n",
        "    (\"Response Validators\", \"Cloud Run API\"),\n",
        "    (\"Cloud Run API\", \"React Frontend\"),\n",
        "    (\"Cloud Run API\", \"Cloud Logging\"),\n",
        "]\n",
        "\n",
        "G = nx.DiGraph()\n",
        "G.add_nodes_from(flow_nodes)\n",
        "G.add_edges_from(flow_edges)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "pos = {\n",
        "    \"Resident Web Chat\": (-1.0, 0.2),\n",
        "    \"React Frontend\": (-0.4, 0.2),\n",
        "    \"Cloud Run API\": (0.2, 0.2),\n",
        "    \"Prompt Filters\": (0.6, 0.8),\n",
        "    \"Dialogflow Data Store\": (1.0, 0.8),\n",
        "    \"Gemini Model\": (1.4, 0.2),\n",
        "    \"Response Validators\": (0.6, -0.4),\n",
        "    \"Cloud Logging\": (0.6, -0.9),\n",
        "}\n",
        "\n",
        "nx.draw_networkx_nodes(G, pos, node_size=2200, node_color=\"#1f77b4\", alpha=0.9)\n",
        "nx.draw_networkx_labels(G, pos, font_size=9, font_color=\"white\")\n",
        "nx.draw_networkx_edges(G, pos, arrows=True, arrowstyle=\"-|>\", arrowsize=15, width=2, edge_color=\"#555\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"ADS Snow Agent Flow Diagram\", fontsize=14)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Executive Demo Checklist\n",
        "\n",
        "- Start with architecture slide using the generated diagram.\n",
        "- Run the ingestion notebook cells up to `initialize_dialogflow_datastore` in dry-run mode.\n",
        "- Demo the Cloud Run chat endpoint with pre-vetted scenarios and show logs in real time.\n",
        "- Present evaluation metrics and safety test results to address accuracy and risk.\n",
        "- Close with cost projection, rollout phases, and governance milestones.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
